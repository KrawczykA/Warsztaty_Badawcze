{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9919135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\programowanie\\studia\\sem6\\WB2\\.venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "e:\\programowanie\\studia\\sem6\\WB2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from lightly.transforms import SimCLRTransform, DINOTransform, MAETransform, MoCoV2Transform, utils\n",
    "from datasets import create_dataset\n",
    "from models import MAEModel\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import copy\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from pathlib import Path\n",
    "from models import BYOLModel, SimCLRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6286744a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eval' from 'e:\\\\programowanie\\\\studia\\\\sem6\\\\WB2\\\\projekt\\\\eval.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import eval\n",
    "import importlib\n",
    "import models\n",
    "from eval import *\n",
    "importlib.reload(models)\n",
    "importlib.reload(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb300b1",
   "metadata": {},
   "source": [
    "# 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a05a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating simclr trained on cifar100, testing on cifar10\n",
      "Checkpoint: ./checkpoints/cifar100/simclr/ran-2/model_epoch_19.ckpt\n",
      "Loading simclr model: {'train_dataset': 'cifar100', 'method': 'simclr', 'version': 'ran-2', 'filename': 'model_epoch_19.ckpt', 'pretrained': False, 'lr': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 196/196 [00:27<00:00,  7.07it/s]\n",
      "Extracting features: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | model        | Sequential         | 11.2 M | train\n",
      "1 | criterion    | CrossEntropyLoss   | 0      | train\n",
      "2 | train_metric | MulticlassAccuracy | 0      | train\n",
      "3 | val_metric   | MulticlassAccuracy | 0      | train\n",
      "4 | test_metric  | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "67        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 196/196 [00:38<00:00,  5.07it/s, v_num=11, train_loss=1.810, val_loss=1.790, val_acc=0.352, train_acc=0.358]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 196/196 [00:38<00:00,  5.04it/s, v_num=11, train_loss=1.810, val_loss=1.790, val_acc=0.352, train_acc=0.358]\n",
      "Linear Probing Accuracy: 0.3521\n",
      "Best k-NN Accuracy: 0.3059 (k=50)\n",
      "\n",
      "k-NN Results:\n",
      "  k=5: 0.2542\n",
      "  k=10: 0.2824\n",
      "  k=20: 0.2947\n",
      "  k=50: 0.3059\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "\n",
    "result = evaluate_single(\n",
    "    checkpoint_path=\"./checkpoints/cifar100/simclr/ran-2/model_epoch_19.ckpt\",\n",
    "    method=\"simclr\",\n",
    "    train_dataset=\"cifar100\",\n",
    "    test_dataset=\"cifar10\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(f\"Linear Probing Accuracy: {result['linear_probing_accuracy']:.4f}\")\n",
    "print(f\"Best k-NN Accuracy: {result['best_knn_accuracy']:.4f} (k={result['best_knn_k']})\")\n",
    "print(\"\\nk-NN Results:\")\n",
    "for k, acc in result['knn_results'].items():\n",
    "    print(f\"  k={k}: {acc:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Porównanie różnych hiperparametrów tego samego modelu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1788b",
   "metadata": {},
   "source": [
    "# porównanie hiperparametrów per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a6ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating mae trained on cifar100, testing on cifar10\n",
      "Checkpoint: ./checkpoints/cifar100/mae/ran-290/model_epoch_20.ckpt\n",
      "Loading mae model: {'train_dataset': 'cifar100', 'method': 'mae', 'version': 'ran-290', 'filename': 'model_epoch_20.ckpt', 'pretrained': False, 'lr': 0.01, 'hyperparam': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 196/196 [00:23<00:00,  8.45it/s]\n",
      "Extracting features: 100%|██████████| 40/40 [00:19<00:00,  2.06it/s]\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | model        | Sequential         | 11.2 M | train\n",
      "1 | criterion    | CrossEntropyLoss   | 0      | train\n",
      "2 | train_metric | MulticlassAccuracy | 0      | train\n",
      "3 | val_metric   | MulticlassAccuracy | 0      | train\n",
      "4 | test_metric  | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "67        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/196 [00:00<?, ?it/s, v_num=12, train_loss=2.300, val_loss=2.300, val_acc=0.101, train_acc=0.0976]          "
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = SSLEvaluator(config)\n",
    "results = []\n",
    "\n",
    "# Lista ścieżek do różnych wersji SimCLR\n",
    "mae_versions = [\n",
    "    (\"./checkpoints/cifar100/mae/ran-290/model_epoch_20.ckpt\", \"random, lr=0.01, mask_ratio=0.9\"),\n",
    "    (\"./checkpoints/cifar100/mae/pre-290/model_epoch_20.ckpt\", \"pre-trained, lr=0.01, mask_ratio=0.9\"),\n",
    "\n",
    "]\n",
    "\n",
    "for checkpoint_path, version_name in mae_versions:\n",
    "    result = evaluator.evaluate_single_model(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        method=\"mae\",\n",
    "        train_dataset=\"cifar100\",\n",
    "        test_dataset=\"cifar10\",\n",
    "        hyperparameter_info=version_name\n",
    "    )\n",
    "    results.append(result)\n",
    "\n",
    "# Wizualizacja porównania\n",
    "df_comparison = pd.DataFrame(results)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Linear probing\n",
    "ax1.bar(df_comparison['hyperparameters'], df_comparison['linear_probing_accuracy'])\n",
    "ax1.set_title('Linear Probing Accuracy - SimCLR Variants')\n",
    "ax1.set_xlabel('Version')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# k-NN\n",
    "ax2.bar(df_comparison['hyperparameters'], df_comparison['best_knn_accuracy'])\n",
    "ax2.set_title('Best k-NN Accuracy - SimCLR Variants')\n",
    "ax2.set_xlabel('Version')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f07623",
   "metadata": {},
   "source": [
    "# WSSZYTSKIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a1c142ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating mae trained on cifar100, testing on cifar10\n",
      "Checkpoint: ./checkpoints\\cifar100\\mae\\pre-275\\model_epoch_10.ckpt\n",
      "Loading mae model: {'train_dataset': 'cifar100', 'method': 'mae', 'version': 'pre-275', 'filename': 'model_epoch_10.ckpt', 'pretrained': True, 'lr': 0.01, 'hyperparam': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 196/196 [00:41<00:00,  4.73it/s]\n",
      "Extracting features: 100%|██████████| 40/40 [00:25<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating mae trained on cifar100, testing on cifar100\n",
      "Checkpoint: ./checkpoints\\cifar100\\mae\\pre-275\\model_epoch_10.ckpt\n",
      "Loading mae model: {'train_dataset': 'cifar100', 'method': 'mae', 'version': 'pre-275', 'filename': 'model_epoch_10.ckpt', 'pretrained': True, 'lr': 0.01, 'hyperparam': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/196 [00:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[193], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# ## 3. Pełna ewaluacja wszystkich modeli\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# %% Przykład 3: Kompletna ewaluacja\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Uruchom pełną ewaluację (może zająć dużo czasu!)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_complete_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Wyświetl podsumowanie\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== EVALUATION SUMMARY ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\xd.py:531\u001b[0m, in \u001b[0;36mrun_complete_evaluation\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    529\u001b[0m set_seed(config\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m    530\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m SSLEvaluator(config)\n\u001b[1;32m--> 531\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_full_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mcreate_summary_report(results_df)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_df\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\xd.py:451\u001b[0m, in \u001b[0;36mSSLEvaluator.run_full_evaluation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[38;5;66;03m# Ewaluacja na różnych datasetach testowych\u001b[39;00m\n\u001b[0;32m    450\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m test_dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtest_datasets:\n\u001b[1;32m--> 451\u001b[0m                         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_single_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion_dir\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m                         all_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;66;03m# Ewaluacja baseline methods\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\xd.py:332\u001b[0m, in \u001b[0;36mSSLEvaluator.evaluate_single_model\u001b[1;34m(self, checkpoint_path, method, train_dataset, test_dataset, hyperparameter_info)\u001b[0m\n\u001b[0;32m    328\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size, \n\u001b[0;32m    329\u001b[0m                        shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_workers)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# Ekstrakcja cech\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m train_features, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m test_features, test_labels \u001b[38;5;241m=\u001b[39m extract_features(model, test_loader, \n\u001b[0;32m    335\u001b[0m                                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice, method)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# Linear probing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\xd.py:174\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(model, dataloader, device, method)\u001b[0m\n\u001b[0;32m    171\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting features\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    175\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m# Różne metody mogą mieć różne sposoby ekstrakcji cech\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:491\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:422\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1139\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\studia\\Sem 6\\WB\\Warsztaty_Badawcze\\.conda\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "results_df = run_complete_evaluation(config)\n",
    "\n",
    "# Wyświetl podsumowanie\n",
    "print(\"=== EVALUATION SUMMARY ===\")\n",
    "print(f\"Total models evaluated: {len(results_df)}\")\n",
    "print(f\"\\nTop 5 models (Linear Probing):\")\n",
    "print(results_df.nlargest(5, 'linear_probing_accuracy')[\n",
    "    ['method', 'train_dataset', 'test_dataset', 'linear_probing_accuracy']\n",
    "])\n",
    "\n",
    "print(f\"\\nTop 5 models (k-NN):\")\n",
    "print(results_df.nlargest(5, 'best_knn_accuracy')[\n",
    "    ['method', 'train_dataset', 'test_dataset', 'best_knn_accuracy', 'best_knn_k']\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7f8615",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m method_stats \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear_probing_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_knn_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m })\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Performance by Method ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(method_stats)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "method_stats = results_df.groupby('method').agg({\n",
    "    'linear_probing_accuracy': ['mean', 'std', 'max'],\n",
    "    'best_knn_accuracy': ['mean', 'std', 'max']\n",
    "}).round(4)\n",
    "\n",
    "print(\"=== Performance by Method ===\")\n",
    "print(method_stats)\n",
    "\n",
    "# Wizualizacja\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Box plot dla linear probing\n",
    "results_df.boxplot(column='linear_probing_accuracy', by='method', ax=axes[0,0])\n",
    "axes[0,0].set_title('Linear Probing Accuracy by Method')\n",
    "\n",
    "# Box plot dla k-NN\n",
    "results_df.boxplot(column='best_knn_accuracy', by='method', ax=axes[0,1])\n",
    "axes[0,1].set_title('k-NN Accuracy by Method')\n",
    "\n",
    "# Heatmap dla różnych wartości k\n",
    "knn_data = []\n",
    "for _, row in results_df.iterrows():\n",
    "    if 'knn_results' in row and row['knn_results']:\n",
    "        for k, acc in row['knn_results'].items():\n",
    "            knn_data.append({\n",
    "                'method': row['method'],\n",
    "                'k': k,\n",
    "                'accuracy': acc\n",
    "            })\n",
    "\n",
    "knn_df = pd.DataFrame(knn_data)\n",
    "knn_pivot = knn_df.pivot_table(values='accuracy', index='method', columns='k', aggfunc='mean')\n",
    "sns.heatmap(knn_pivot, annot=True, fmt='.3f', ax=axes[1,0], cmap='viridis')\n",
    "axes[1,0].set_title('Average k-NN Accuracy Heatmap')\n",
    "\n",
    "# Scatter plot: train vs test dataset performance\n",
    "for method in results_df['method'].unique():\n",
    "    method_data = results_df[results_df['method'] == method]\n",
    "    axes[1,1].scatter(method_data['train_dataset'], \n",
    "                      method_data['linear_probing_accuracy'],\n",
    "                      label=method, s=100, alpha=0.7)\n",
    "axes[1,1].set_xlabel('Training Dataset')\n",
    "axes[1,1].set_ylabel('Linear Probing Accuracy')\n",
    "axes[1,1].set_title('Performance by Training Dataset')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773f10c",
   "metadata": {},
   "source": [
    "# CROSS-DATASET PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5a7d09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cross_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[38;5;241m.\u001b[39mpivot_table(\n\u001b[0;32m      2\u001b[0m     values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear_probing_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m     columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Cross-Dataset Performance Matrix ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(cross_dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cross_dataset = results_df.pivot_table(\n",
    "    values='linear_probing_accuracy',\n",
    "    index=['method', 'train_dataset'],\n",
    "    columns='test_dataset',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(\"=== Cross-Dataset Performance Matrix ===\")\n",
    "print(cross_dataset)\n",
    "\n",
    "# Wizualizacja\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cross_dataset, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            vmin=0.5, vmax=1.0, center=0.75)\n",
    "plt.title('Cross-Dataset Performance Heatmap\\n(Train Dataset → Test Dataset)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa87b1",
   "metadata": {},
   "source": [
    "# EKSPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0771968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df.to_csv('detailed_evaluation_results.csv', index=False)\n",
    "results_df.to_excel('detailed_evaluation_results.xlsx', index=False)\n",
    "\n",
    "# Stwórz raport tekstowy\n",
    "with open('evaluation_summary.txt', 'w') as f:\n",
    "    f.write(\"SSL Model Evaluation Summary\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Best Overall Model:\\n\")\n",
    "    best_model = results_df.loc[results_df['linear_probing_accuracy'].idxmax()]\n",
    "    f.write(f\"  Method: {best_model['method']}\\n\")\n",
    "    f.write(f\"  Training Dataset: {best_model['train_dataset']}\\n\")\n",
    "    f.write(f\"  Test Dataset: {best_model['test_dataset']}\\n\")\n",
    "    f.write(f\"  Linear Probing Accuracy: {best_model['linear_probing_accuracy']:.4f}\\n\")\n",
    "    f.write(f\"  Best k-NN Accuracy: {best_model['best_knn_accuracy']:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Method Rankings (Average Linear Probing Accuracy):\\n\")\n",
    "    method_ranking = results_df.groupby('method')['linear_probing_accuracy'].mean().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
