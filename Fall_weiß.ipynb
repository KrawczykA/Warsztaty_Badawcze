{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPriciDF+Y9uRKrj6UKwU8a",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KrawczykA/Warsztaty_Badawcze/blob/kingston/Fall_wei%C3%9F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install lightly"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_wS-lRf4xso",
    "outputId": "daf75a54-199e-40a3-b03d-df630762f9a1"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting lightly\n",
      "  Downloading lightly-1.5.20-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from lightly) (2025.4.26)\n",
      "Collecting hydra-core>=1.0.0 (from lightly)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lightly_utils~=0.0.0 (from lightly)\n",
      "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.0.2)\n",
      "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.32.3)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from lightly) (1.17.0)\n",
      "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.11/dist-packages (from lightly) (4.67.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from lightly) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from lightly) (0.21.0+cu124)\n",
      "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.11.4)\n",
      "Collecting pytorch_lightning>=1.0.4 (from lightly)\n",
      "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.4.0)\n",
      "Collecting aenum>=3.1.11 (from lightly)\n",
      "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (24.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from lightly_utils~=0.0.0->lightly) (11.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (0.4.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2025.3.2)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly) (3.10)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->lightly)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->lightly)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->lightly)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->lightly)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->lightly)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->lightly)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->lightly)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->lightly)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->lightly)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->lightly)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->lightly) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.11.15)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly) (75.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->lightly) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.20.0)\n",
      "Downloading lightly-1.5.20-py3-none-any.whl (851 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m851.6/851.6 kB\u001B[0m \u001B[31m41.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m165.6/165.6 kB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.5/154.5 kB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
      "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.1/823.1 kB\u001B[0m \u001B[31m47.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m62.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m35.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m44.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m78.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m962.5/962.5 kB\u001B[0m \u001B[31m57.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: aenum, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, lightly_utils, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning, lightly\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed aenum-3.1.16 hydra-core-1.3.2 lightly-1.5.20 lightly_utils-0.0.2 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_lightning-2.5.1.post0 torchmetrics-1.7.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#1. importy (nie mam zielonego pojęcia czy wszystkie potrzebne nie mam tez zielonego pojęcia czy colab się na nie nie obrazi)"
   ],
   "metadata": {
    "id": "Rb_mlrmB489D"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ov4P9MBQ4Uv8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm\n",
    "from lightly.loss import NTXentLoss, DINOLoss\n",
    "from lightly.models.modules.heads import SimCLRProjectionHead, BYOLProjectionHead, BYOLPredictionHead\n",
    "from lightly.models.utils import update_momentum, deactivate_requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#2. Przygotowanie zbioru danych (wykonane razy liczba zbiorów danych)"
   ],
   "metadata": {
    "id": "ixNmhCZ15AHo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## W tej sekcji chcemy uzyskać 4 datasety:\n",
    "\n",
    "\n",
    "1.   train_ssl_dataset - do użycia podczas SSL jak nazwa wskazuje\n",
    "2.   train_dataset - do trenowania projection heada\n",
    "3.   train_full_dataset - połączone oba powyższe do trenowania prymitywnego modelu\n",
    "4.   test_dataset - do ewaluacji zarówno SSL jak i samej klasyfikacji\n",
    "\n",
    "w przypadku każdego datasetu będą potrzebne różne tranformacje (jak w notebooku week 5 Part II)\n",
    "\n",
    "Biorąc pod uwagę terminy do poniedziałku wieczór kod robiący te datasety dla każdego rozważanego zbioru musi być gotowy.\n",
    "\n"
   ],
   "metadata": {
    "id": "mkuW081C5INb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def create_dataset(set_name, SSL_proportion, train_transform, train_full_transform, test_transform, path_to_data, seed=42, download=True):\n",
    "    if set_name == 'CIFAR10':\n",
    "        train_ssl_dataset = torchvision.datasets.CIFAR10(root=path_to_data, train=True, transform=train_transform, download=download)\n",
    "        train_full_dataset = torchvision.datasets.CIFAR10(root=path_to_data, train=True, transform=train_full_transform, download=download)\n",
    "        test_dataset = torchvision.datasets.CIFAR10(root=path_to_data, train=False, transform=test_transform, download=download)\n",
    "    elif set_name == 'CIFAR100':\n",
    "        train_ssl_dataset = torchvision.datasets.CIFAR100(root=path_to_data, train=True, transform=train_transform, download=download)\n",
    "        train_full_dataset = torchvision.datasets.CIFAR100(root=path_to_data, train=True, transform=train_full_transform, download=download)\n",
    "        test_dataset = torchvision.datasets.CIFAR100(root=path_to_data, train=False, transform=test_transform, download=download)\n",
    "    #a bit different logic you have to have dataset already downloaded and restructured\n",
    "    else:\n",
    "        train_path = os.path.join(path_to_data, 'imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train')\n",
    "        test_path = os.path.join(path_to_data, 'imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/val_restructured')\n",
    "        train_ssl_dataset = torchvision.datasets.ImageFolder(root=train_path, transform=train_transform)\n",
    "        train_full_dataset = torchvision.datasets.ImageFolder(root=train_path, transform=train_full_transform)\n",
    "        test_dataset = torchvision.datasets.ImageFolder(root=test_path, transform=test_transform)\n",
    "\n",
    "    targets = np.array([y for _, y in train_full_dataset])\n",
    "    SSL_indices, classification_indices = train_test_split(\n",
    "        np.arange(len(targets)),\n",
    "        test_size=1-SSL_proportion,\n",
    "        random_state=seed,\n",
    "        stratify=targets\n",
    "    )\n",
    "    train_dataset = torch.utils.data.Subset(train_full_dataset, classification_indices)\n",
    "    train_ssl_dataset = torch.utils.data.Subset(train_ssl_dataset, SSL_indices)\n",
    "    print(\"Length of entire train dataset: \", len(train_full_dataset))\n",
    "    print(\"Length of SSL train dataset: \", len(train_ssl_dataset))\n",
    "    print(\"Length of classification train dataset: \", len(train_dataset))\n",
    "    print(\"Length of test dataset: \", len(test_dataset))\n",
    "    return train_full_dataset, train_ssl_dataset, train_dataset, test_dataset\n",
    "\n",
    "# funkcja do restrukturyzacji bazowego pobrania imagenetu (zmodyfikuj bazowe ścieżki jesli trzymasz dane gdzie indziej)\n",
    "\n",
    "def restructure_val_dir(imagenet_val_restructured_dir = \"data/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/val_restructured\",\n",
    "                        imagenet_val_dir = \"data/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/val\",\n",
    "                         imagenet_train_dir = \"data/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\",\n",
    "                         annotations_dir = \"data/imagenet-object-localization-challenge/ILSVRC/Annotations/CLS-LOC\"):\n",
    "    if os.path.exists(imagenet_val_restructured_dir):\n",
    "        print(\"Restructured validation directory already exists.\")\n",
    "        return imagenet_val_restructured_dir\n",
    "\n",
    "    print(\"Restructuring validation directory...\")\n",
    "\n",
    "    # Get the class mapping from training directory\n",
    "    classes = [d.name for d in os.scandir(imagenet_train_dir) if d.is_dir()]\n",
    "\n",
    "    # Create class directories in the restructured validation directory\n",
    "    for class_name in classes:\n",
    "        os.makedirs(os.path.join(imagenet_val_restructured_dir, class_name), exist_ok=True)\n",
    "\n",
    "    # Function to extract class ID from XML annotation file\n",
    "    def get_class_from_annotation(xml_path):\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        # Get the first object's name (class)\n",
    "        obj = root.find('object')\n",
    "        if obj is not None:\n",
    "            return obj.find('name').text\n",
    "        return None\n",
    "\n",
    "    # Process each validation image\n",
    "    for img_name in os.listdir(imagenet_val_dir):\n",
    "        if not img_name.endswith('.JPEG'):\n",
    "            continue\n",
    "\n",
    "        # Get base name without extension\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "\n",
    "        # Find corresponding annotation file\n",
    "        xml_path = os.path.join(annotations_dir, base_name + '.xml')\n",
    "\n",
    "        if os.path.exists(xml_path):\n",
    "            class_name = get_class_from_annotation(xml_path)\n",
    "            if class_name and class_name in classes:\n",
    "                # Copy image to the appropriate class directory\n",
    "                src_path = os.path.join(imagenet_val_dir, img_name)\n",
    "                dst_path = os.path.join(imagenet_val_restructured_dir, class_name, img_name)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "\n",
    "    print(\"Validation directory restructured successfully.\")\n",
    "    return imagenet_val_restructured_dir"
   ],
   "metadata": {
    "id": "lr9hH0q784DW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Przygotowanie pipelinów treningowych"
   ],
   "metadata": {
    "id": "PFFYagm78LlW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chodzi o stworzenie klas pochodnych pl.LightningModule dla wszystkich badanych architektur i dla ogólnego modelu klasyfikującego (który będzie montowany z modelów SSLowych i classification heada),\n",
    "to wystarczy zrobić tylko raz. Proponuję aby każdy model wytrenować biorąc backbone z resnet18 (jak w notebooku week5), backbone ze struktury resnet18 (bez wyuczonych parametrów), backbone w postaci jakiejś prymitywnej architektury w stylu używanej na neuronkach. Tym sposobem mamy 3 razy więcej wykresików do potencjalnego wstawienia do raportu.\n",
    "\n",
    "**Uwaga** przy trenowaniu modeli SSL, które nie mają pretext tasku jako klasyfikacji, warto (trzeba) wymyślić jakąś metrykę do ewaluacji w notebooku *copy_of_week5* jest to zrobione jako porównywanie z k-meanes metrykami ARI i NMI. Można wymyślić coś innego można zostawić to."
   ],
   "metadata": {
    "id": "Ruj9z_qT8oYr"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tEUdelDA4svz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Trenowanie - szacowany czas pracy człowieka niewiele jeśli nic nie będzie zabugowane czas obliczeń zasadniczo nie wiadomo."
   ],
   "metadata": {
    "id": "9NFGUYIgA9hC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " W skład tego będzie wchodzić trenowanie SSL (raz) trenowanie klasyfikatora z zamrożoną częścią SSL-ową (dwa) i trenowanie klasyfikatora wraz z częścią SSL-ową (trzy). W schemat raz dwa trzy nie wlicza się model prymitywny trenowany tylko raz.\n",
    "\n",
    " Ważne z punktu widzenia raportowego będą wykresiki metryk z procesu uczenia, w tytułach wykresów warto zapisywać końcowe wartości metryk chyba, że ktoś ma inny foolproof sposób przechowywania.\n",
    "\n",
    " Warto byłoby (niewiadomo czy czas pozwoli) przeczesać choć niewielką siatkę hiperparametrów w stylu lr = [0.01, 0.001, 0.0001], num_epochs = [5, 15, 30] (zachowajmy stałą liczbę epok 10 dla uczenia classification heada - w tej sytuacji model prymitywny uczyłby się [15, 25, 40] epok). Do tego z trzy różne wartości innego hiperparametru w modelach które takie mają (np. temperatura softmaxa w DINO)\n",
    "\n",
    " Trzeba uważać tutaj na nazewnictwo zmiennych bo zaskakująco szybko kończy się słownictwo i łatwo o nadpisanie czegoś co się trenowało godzinę (nie mam zielonego pojęcia skad ta uwaga).\n",
    "\n",
    " Na koniec tego kroku będziemy chcieli mieć zmienne nie wiem do końca jakiego typu ale takiego żeby kod z *Part XIV* w *week_5.ipnyb* mógł być na nich odpalony (wymaganie interfacowe). W *copy_of_week5* działają  jak można zobaczyć różne typy."
   ],
   "metadata": {
    "id": "3me0N9RqBJFX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. PCA dla każdego zbioru danych"
   ],
   "metadata": {
    "id": "OPDRd619C0dO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Autodeksryptywne mam nadzieję"
   ],
   "metadata": {
    "id": "AozHkzvJC54v"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Porównanie wyników"
   ],
   "metadata": {
    "id": "t_Yf5F7jD9VE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zakładając, że mamy modele w postaci w z punktu 4. to jest to już na szczęście czysty copypasting z *week5.ipynb*"
   ],
   "metadata": {
    "id": "pCKmWy7ME2SS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Raport"
   ],
   "metadata": {
    "id": "aAhONsFKFlV_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "w wiadomym notebooku są już piękne pytania raportowe, na które powinno być łatwo odpowiedzieć zakładając, że mamy wszystkie obrazki"
   ],
   "metadata": {
    "id": "hnP-CUjxFpRm"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Xo4HkIz9BH6p"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
